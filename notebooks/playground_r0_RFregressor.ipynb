{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### import statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "sys.path.append('../src')\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_percentage_error\n",
    "from plot_utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F_INPUT = '../../data/v2/data.h5'\n",
    "ds_label_all = 'r0' # ds stands for data source\n",
    "ds_label_day = 'r0_day'\n",
    "ds_label_ngt = 'r0_night'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DENSE_SUBSET_START = '2018-05-03'\n",
    "DENSE_SUBSET_END = '2020-12-30'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smooth_mins = [1, 2, 5, 10, 15, 20]\n",
    "r0_map = {'all':'r0_all','day':'r0_day','ngt':'r0_ngt'} # adn = all, day, ngt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feats_mnus_cn2 = ['pressure', 'relative_humidity', 'temperature', 'wind_speed', 'solar_zenith_angle','dayofyear', 'hour']\n",
    "feats_plus_cn2 = feats_mnus_cn2 + ['logCn2']\n",
    "# feats_map = {'feats_plus_cn2': feats_plus_cn2, 'feats_mnus_cn2': feats_mnus_cn2}\n",
    "feats_map = {'feats_plus_cn2': feats_plus_cn2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xmin, ymin = 0, 0\n",
    "# xmax, ymax = 20, 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_hdf(F_INPUT, 'merged')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### add new features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['dayofyear'] = df.index.dayofyear\n",
    "df['hour'] = df.index.hour\n",
    "df['logCn2'] = np.log10(df['Cn2'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### applying smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for m in smooth_mins:\n",
    "    for ds_label in [ds_label_all, ds_label_day, ds_label_ngt]:\n",
    "        if ds_label == 'r0':\n",
    "            label = ds_label + '_all_{}T'.format(m)\n",
    "        elif ds_label == 'r0_night':\n",
    "            label = 'r0_ngt_{}T'.format(m)\n",
    "        else:\n",
    "            label = ds_label + '_{}T'.format(m)\n",
    "        if m == 1:\n",
    "            df[label] = df[ds_label]\n",
    "        else:\n",
    "            df[label] = df[ds_label].rolling('{}T'.format(m)).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### restricting data to usable, relatively dense subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_subset = df[(df.index > DENSE_SUBSET_START) & (df.index < DENSE_SUBSET_END)]\n",
    "df_subset.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### resampling back down to 5 mins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_subset_resamp5 = df_subset.resample('5 min').median()\n",
    "df_subset_resamp5.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_subset_resamp5.to_hdf('df_subset_resamp5.r0.h5', 'df_subset_resamp5')\n",
    "df_subset = df_subset_resamp5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "### taking the train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "split_date = '2019-12-31'\n",
    "train = df_subset.index <= split_date\n",
    "test  = df_subset.index > split_date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### creating non-nan masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_masks = {}\n",
    "for f in feats_map.keys(): \n",
    "    valid_masks[f] = {}\n",
    "    for r in r0_map.keys():\n",
    "        valid_masks[f][r] = {}\n",
    "        for m in smooth_mins:\n",
    "            label = '{}_{}T'.format(r0_map[r], str(m))\n",
    "            feats_plus_label = feats_map[f] + [label]\n",
    "            valid_masks[f][r][m] = ~df_subset[feats_plus_label].isnull().any(axis=1)\n",
    "            print(\"{} {} {:2} {:7} {:7} {:7}\".format(f, r, m, valid_masks[f][r][m].shape[0], np.sum(train & valid_masks[f][r][m]), np.sum(test & valid_masks[f][r][m])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('valid_masks.r0.pkl', 'wb') as fh:\n",
    "    pickle.dump(valid_masks, fh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### train and test subroutine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "regr = RandomForestRegressor(n_estimators=100, random_state=0)\n",
    "\n",
    "def train_and_test(train_df, test_df, feats, label):\n",
    "    forest = regr.fit(train_df[feats], train_df[label])\n",
    "#     r2 = regr.score(test_df[feats], test_df[label])\n",
    "    preds = regr.predict(test_df[feats])\n",
    "    r2 = r2_score(test_df[label], preds)\n",
    "    sq_err = mean_squared_error(test_df[label], preds)\n",
    "    perc_err = mean_absolute_percentage_error(test_df[label], preds)\n",
    "#     return {'forest': forest, 'preds': preds, 'r2': r2, 'sq_err': sq_err, 'perc_err': perc_err}\n",
    "    return {'preds': preds, 'r2': r2, 'sq_err': sq_err, 'perc_err': perc_err}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get All Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "for f in feats_map.keys(): \n",
    "    results[f] = {}\n",
    "    for r in r0_map.keys():\n",
    "        results[f][r] = {}\n",
    "        for m in smooth_mins:\n",
    "            print(\"Progress: {} {} {}\".format(f, r, m))\n",
    "            label = '{}_{}T'.format(r0_map[r], str(m))\n",
    "            feats = feats_map[f]\n",
    "            valid = valid_masks[f][r][m]\n",
    "            results[f][r][m] = train_and_test(df_subset.loc[train & valid], df_subset.loc[test & valid], feats, label)\n",
    "            with open('results.r0.pkl', 'wb') as fh:\n",
    "                pickle.dump(results, fh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare all Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for r in [ results_all_1T, results_all_2T, results_all_5T, results_all_10T, results_all_15T, results_all_20T ]:\n",
    "#     print(f\"{r['r2']:.5},{r['sq_err']:.5},{r['perc_err']:.5}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for r in [ results_day_1T, results_day_2T, results_day_5T, results_day_10T, results_day_15T, results_day_20T ]:\n",
    "#     print(f\"{r['r2']:.5},{r['sq_err']:.5},{r['perc_err']:.5}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for r in [ results_night_1T, results_night_2T, results_night_5T, results_night_10T, results_night_15T, results_night_20T ]:\n",
    "#     print(f\"{r['r2']:.5},{r['sq_err']:.5},{r['perc_err']:.5}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scatter_with_errors(test_truth_day, test_preds_day, test_perc_err_day, xmin, xmax, ymin, ymax)\n",
    "# plot_importance(regr, df_subset.loc[train&valid_day,feats], feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scatter_with_errors(test_truth_day, test_preds_day, test_perc_err_day, xmin, xmax, ymin, ymax)\n",
    "# plot_importance(regr, df_subset.loc[train&valid_day,feats], feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# error_by_r0_histograms(test_truth_all, error_perc(test_truth_all, test_preds_all), 0, 80)\n",
    "# error_by_r0_histograms(test_truth_day, error_perc(test_truth_day, test_preds_day), 0, 80)\n",
    "# error_by_r0_histograms(test_truth_night, error_perc(test_truth_night, test_preds_night), 0, 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_truth_night = df_subset.loc[test&valid_night,label_night]\n",
    "# test_truth_day = df_subset.loc[test&valid_day,label_day]\n",
    "# test_truth_all = df_subset.loc[test&valid,label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_truth_night_15T = df_subset.loc[test&valid_night,'r0_night_15T']\n",
    "# test_pred_night_15T = results_night_10T['preds']\n",
    "# error_by_r0_histograms(test_truth_night_15T, error_perc(test_truth_night_15T, test_pred_night_15T), 0, 80)\n",
    "# scatter_with_errors(test_truth_night_15T, test_pred_night_15T, error_perc, xmin, xmax, ymin, ymax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_truth_day_15T = df_subset.loc[test&valid_day,'r0_day_15T']\n",
    "# test_pred_day_15T = results_day_15T['preds']\n",
    "# error_by_r0_histograms(test_truth_day_15T, error_perc(test_truth_day_15T, test_pred_day_15T), 0, 90)\n",
    "# scatter_with_errors(test_truth_day_15T, test_pred_day_15T, error_perc, xmin, xmax, ymin, ymax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "#### scatter plots of actual vs. predict using error_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib inline\n",
    "# scatter_with_errors(test_truth_all, test_preds_all, error_perc, xmin, xmax, ymin, ymax)\n",
    "\n",
    "# scatter_with_errors(test_truth_night, test_preds_night, error_perc, xmin, xmax, ymin, ymax)\n",
    "# plot_importance(regr, df_subset.loc[train&valid_night,feats], feats)\n",
    "\n",
    "# scatter_with_errors(test_truth_night, test_preds_night, error_perc, xmin, xmax, ymin, ymax)\n",
    "# plot_importance(regr, df_subset.loc[train&valid_night,feats], feats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### interactive time domain plot of errors\n",
    "\n",
    "switching matplotlib to notebook mode to enable a zoom-in of different portions of the time axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib notebook \n",
    "# plot_errors_in_time(test_truth_all, test_preds_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### feature importance\n",
    "\n",
    "feature importance from the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_importance(regr, df_subset.loc[train&valid,feats], feats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## debug why CN2 is so low\n",
    "\n",
    "#### What happens if I drop month and SZA\n",
    "\n",
    "Answer: turns out we had to take the log of CN2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feats_no_sza = ['pressure', 'relative_humidity', 'temperature', 'wind_speed', 'logCn2']\n",
    "# preds_all_no_sza, r2_all_no_sza = train_and_test(df_subset.loc[train & valid], df_subset.loc[test & valid], feats_no_sza, label)\n",
    "# scatter_with_errors(test_truth_all, preds_all_no_sza, error_perc, xmin, xmax, ymin, ymax)\n",
    "# plot_importance(regr, df_subset.loc[train&valid,feats_no_sza], feats_no_sza)\n",
    "# r2_all_no_sza"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### correlation between the signals using [stats.pearsonr](https://towardsdatascience.com/four-ways-to-quantify-synchrony-between-time-series-data-b99136c4a9c9)\n",
    "\n",
    "We calculate:\n",
    "- overall synchrony between r0 and Cn2\n",
    "- local synchrony between r0 and Cn2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Overall Synchrony"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # r, p = print_pearsonr(df_subset.loc[train&valid,label], df_subset.loc[train&valid,'logCn2'])\n",
    "# plot_overall_synchrony(df_subset.loc[train&valid,label], df_subset.loc[train&valid,['logCn2']], label, 'logCn2', r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Local Synchrony"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_local_synchrony(df_subset.loc[train&valid,label], df_subset.loc[train&valid,['logCn2']], label, 'Cn2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Synchrony using only R0 daytime data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Overall Synchrony"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# r, p = print_pearsonr(df_subset.loc[train&valid_day,label_day], df_subset.loc[train&valid_day,'logCn2'])\n",
    "# r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_overall_synchrony(df_subset.loc[train&valid_day,label_day], df_subset.loc[train&valid_day,['logCn2']], label_day, 'logCn2', r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Local Synchrony"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_local_synchrony(df_subset.loc[train&valid_day,label_day], df_subset.loc[train&valid_day,['logCn2']], label_day, 'logCn2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try comparing results without CN2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results_all_15T_nocn2 = train_and_test(df_subset.loc[train & valid], df_subset.loc[test & valid], feats_minus_cn2, 'r0_15T')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results_day_15T_nocn2 = train_and_test(df_subset.loc[train & valid_day], df_subset.loc[test & valid_day], feats_minus_cn2, 'r0_day_15T')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results_night_15T_nocn2 = train_and_test(df_subset.loc[train & valid_night], df_subset.loc[test & valid_night], feats_minus_cn2, 'r0_night_15T')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for r in [ results_all_15T, results_all_15T_nocn2 ]:\n",
    "#     print(f\"{r['r2']:.5},{r['sq_err']:.5},{r['perc_err']:.5}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for r in [ results_day_15T, results_day_15T_nocn2 ]:\n",
    "#     print(f\"{r['r2']:.5},{r['sq_err']:.5},{r['perc_err']:.5}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for r in [ results_night_15T, results_night_15T_nocn2 ]:\n",
    "#     print(f\"{r['r2']:.5},{r['sq_err']:.5},{r['perc_err']:.5}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_importance(results_all_15T['forest'], df_subset.loc[train & valid, feats], feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_truth_night_15T = df_subset.loc[test&valid_night,'r0_night_15T']\n",
    "# test_pred_night_15T = results_night_10T['preds']\n",
    "# error_by_r0_histograms(test_truth_night_15T, error_perc(test_truth_night_15T, test_pred_night_15T), 0, 80)\n",
    "# scatter_with_errors(test_truth_night_15T, test_pred_night_15T, error_perc, xmin, xmax, ymin, ymax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why R2 so weird?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"{:.5}\".format(np.var(df_subset.loc[test&valid_night,'r0_night'])))\n",
    "# print(\"{:.5}\".format(np.var(df_subset.loc[test&valid_night,'r0_night_2T'])))\n",
    "# print(\"{:.5}\".format(np.var(df_subset.loc[test&valid_night,'r0_night_5T'])))\n",
    "# print(\"{:.5}\".format(np.var(df_subset.loc[test&valid_night,'r0_night_10T'])))\n",
    "# print(\"{:.5}\".format(np.var(df_subset.loc[test&valid_night,'r0_night_15T'])))\n",
    "# print(\"{:.5}\".format(np.var(df_subset.loc[test&valid_night,'r0_night_20T'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot One Day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def plot_one_day(preds, smooth_df, orig_df, startdate, enddate):\n",
    "\n",
    "#     preds_df = pd.DataFrame(preds, index=smooth_df.index) \n",
    "\n",
    "#     daymask = (orig_df.index > startdate ) & (orig_df.index < enddate)\n",
    "\n",
    "#     plt.figure(figsize=(20, 5))\n",
    "#     plt.plot(orig_df[daymask], 'g.', label='r0')\n",
    "#     plt.plot(smooth_df[daymask], 'b.', label='r0 smoothed (15min)')\n",
    "#     plt.plot(preds_df[daymask], 'r.', label='preds')\n",
    "#     plt.ylabel('r0')\n",
    "#     plt.legend()\n",
    "#     return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_one_day(results_all_15T['preds'], df_subset.loc[test & valid, 'r0_15T'], df_subset.loc[test & valid, 'r0'], '2020-05-30 04:00', '2020-05-31')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_one_day(results_all_15T['preds'], df_subset.loc[test & valid, 'r0_15T'], df_subset.loc[test & valid, 'r0'], '2020-08-30 04:00', '2020-08-31 00:00')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_one_day(results_all_15T['preds'], df_subset.loc[test & valid, 'r0_15T'], df_subset.loc[test & valid, 'r0'], '2020-02-15 04:00', '2020-02-16 00:00')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_one_day(results_all_15T['preds'], df_subset.loc[test & valid, 'r0_15T'], df_subset.loc[test & valid, 'r0'], '2020-11-15 04:00', '2020-11-16 00:00')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
