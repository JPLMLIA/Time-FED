{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "%matplotlib inline\n",
        "\n",
        "import logging\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "\n",
        "from functools          import partial\n",
        "from matplotlib.patches import Patch\n",
        "from matplotlib.ticker  import FormatStrFormatter\n",
        "from types              import SimpleNamespace as SN\n",
        "\n",
        "# Depending on how your environment is setup, may need to tweak the utils import\n",
        "from src.utils import (\n",
        "    load_weather,\n",
        "    load_bls,\n",
        "    load_r0\n",
        ")\n",
        "\n",
        "# Disable warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Disable logger except for errors/exceptions\n",
        "logger = logging.getLogger()\n",
        "logger.setLevel(logging.ERROR)\n",
        "\n",
        "# Set context of seaborn\n",
        "sns.set_context('poster')\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# SET THESE VARIABLES BEFORE EXECUTING THE FUNCTIONS\n",
        "# Do not remove any variable, leave them as default if unsure. Follow the instructions if provided.\n",
        "config = SN(\n",
        "    # Select the dataset and provide the path to the data directory\n",
        "    name = 'weather',       # Options: ['weather', 'bls', 'r0_day', 'r0_night']\n",
        "    path = './Weather Data/',\n",
        "    # Expected files:\n",
        "    # bls         : BLS1820B.mat\n",
        "    # r0_daytime  : fl4.mat\n",
        "    # r0_nighttime: Cyclop1820.mat\n",
        "\n",
        "    # Enable plots to save to the given dir\n",
        "    save = True,\n",
        "    dir  = './plots/weather/',\n",
        "\n",
        "    # Enable plots; see the lower sections of the config to know\n",
        "    plots = SN(\n",
        "        vc    = True,   # Time cadence graphs       # Disables both the global and the per-column cadence graphs\n",
        "        davg  = True,   # Daily average graphs      #\n",
        "        heat  = True,   # Correlation heatmaps      # Disables both the value and nan correlation heatmaps\n",
        "        hists = True,   # Sigma histograms          #\n",
        "        dvt   = True    # Data vs Time scatterplot  # This plot can take awhile to generate, may want to disable if you're running analysis() a lot\n",
        "    ),\n",
        "\n",
        "    ## Additional arguments for tweaking plot generations, defaults generally apply to all datasets\n",
        "    # Args for value_count bar plots\n",
        "    vc = SN(\n",
        "        kind    = 'bar',\n",
        "        title   = 'Distance between Timestamps for {type}', # Optional flags [{type}], type=[config.name, col]\n",
        "        ylabel  = 'Count',\n",
        "        logy    = True,\n",
        "        figsize = (30, 10), # width, height\n",
        "        limits  = (25, 25), # (N, M), plots the first N and last M values, eg. values[:N] + values[-M:]\n",
        "        file    = 'time_cadence_{type}.png', # Optional flags [{type}], type=[config.name, col]\n",
        "        #overrides = {}\n",
        "    ),\n",
        "\n",
        "    # Args for daily average plots\n",
        "    davg = SN(\n",
        "        alpha   = 1,\n",
        "        figsize = (30, 10),\n",
        "        xlabel  = 'Day of the Year',\n",
        "        ylabel  = 'Value',\n",
        "        title   = 'Daily Average Value for {col}',  # Optional flags [{col}], col=df.col\n",
        "        file    = 'daily_average_{col}.png',        # Optional flags [{col}], col=df.col\n",
        "        overrides = {\n",
        "            'bls': {\n",
        "                'logy': True\n",
        "            }\n",
        "        }\n",
        "    ),\n",
        "\n",
        "    # Args for the correlation heatmaps\n",
        "    heat = SN(\n",
        "        method  = 'pearson',    # Pandas df.corr(method=)\n",
        "        annot   = True,         # Annotates the graph with values in the correlation squares\n",
        "        vmin    = -1,           # Minimum value\n",
        "        vmax    = 1,\n",
        "        cmap    = 'RdYlBu',     # Colouring gradient from vmin to vmax\n",
        "        square  = True,         # Makes the correlation squares actually square (False may make them different shaped rectangles)\n",
        "        figsize = (15, 15),\n",
        "        file    = '{type}_correlations.png', # Optional flags [{type}], type=['value', 'nan']\n",
        "        title   = 'Correlation of {type} for {name}', # Optional flags [{name}, {type}], type=['Values', 'NaNs']\n",
        "        #override = {}\n",
        "    ),\n",
        "\n",
        "    # Args for the sigma histograms\n",
        "    hists = SN(\n",
        "        bins  = 109,        # Weather has weird spikes in the bins when N < 109\n",
        "        alpha = 0.3,        # The opacity of the regions, higher is greater opacity\n",
        "        logy  = True,\n",
        "        ylabel = 'Value Count',\n",
        "        xlabel = 'Value',\n",
        "        title  = 'Histogram of {col}, bins={bins}', # Optional flags: [{col}, {bins}]\n",
        "        file   = 'sigma_hist_{col}.png',            # Optional flags: [{col}]\n",
        "        sigmas = {          # Sigma regions to highlight and their corresponding colours\n",
        "            3: 'red',\n",
        "            4: 'orange',\n",
        "            5: 'yellow',\n",
        "            6: 'green',\n",
        "            7: 'blue'\n",
        "        },\n",
        "        colors = SN(        # Sets the colours of the vertical lines at specific points\n",
        "            mean = 'red',\n",
        "            min  = 'black',\n",
        "            max  = 'black',\n",
        "            hist = 'grey'   # Colour of the histogram itself\n",
        "        ),\n",
        "        normalize = False,  # Normalizes the dataframe columns prior to plotting\n",
        "        loc       = 'upper right',  # Location of the legend\n",
        "        figsize   = (20, 10),\n",
        "        #overrides = {}\n",
        "    ),\n",
        "\n",
        "    # Args for the data vs time plot\n",
        "    dvt = SN(\n",
        "        figsize   = (30, 10),\n",
        "        alpha     = 0.7,\n",
        "        ylabel    = 'Value',\n",
        "        title     = 'Data vs Time for {name}',  # Optional flags [{name}], name=config.name\n",
        "        marker    = '+',\n",
        "        normalize = True,   # Normalizes the dataframe columns prior to plotting\n",
        "        file      = 'scatter_data_vs_time.png',\n",
        "        #overrides = {}\n",
        "    )\n",
        ")\n",
        "\n",
        "# View the config object\n",
        "#config\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def show(save='please_set_a_name.png'):\n",
        "    \"\"\"\n",
        "    Shows a plot, saves it if set\n",
        "    \"\"\"\n",
        "    plt.tight_layout()\n",
        "\n",
        "    if config.save:\n",
        "        plt.savefig(f'{config.dir}/{save}')\n",
        "\n",
        "    plt.show()\n",
        "    plt.clf()\n",
        "\n",
        "def data_vs_time(df):\n",
        "    \"\"\"\n",
        "    Plots all the data on a single scatterplot\n",
        "    \"\"\"\n",
        "    if config.dvt.normalize:\n",
        "        df = (df - df.mean()) / (df.max() - df.min())\n",
        "\n",
        "    _, ax = plt.subplots(figsize=config.dvt.figsize)\n",
        "    for col in df:\n",
        "        sns.scatterplot(\n",
        "            x      = df.index.values,\n",
        "            y      = df[col],\n",
        "            label  = col,\n",
        "            ax     = ax,\n",
        "            marker = config.dvt.marker,\n",
        "            alpha  = config.dvt.alpha\n",
        "        )\n",
        "\n",
        "    ax.set_ylabel(config.dvt.ylabel)\n",
        "    ax.set_title(config.dvt.title.format(name=config.name))\n",
        "\n",
        "    show(config.dvt.file)\n",
        "\n",
        "def sigma_hist(col, series, n_bins=109, save=False):\n",
        "    \"\"\"\n",
        "    Generates a histogram for the provided column and highlights the sigma\n",
        "    regions.\n",
        "    \"\"\"\n",
        "    ticks = set()\n",
        "    if config.hists.normalize:\n",
        "        series = (series - series.mean()) / (series.max() - series.min())\n",
        "\n",
        "    # Gather stats\n",
        "    min  = series.min()\n",
        "    max  = series.max()\n",
        "    mean = series.mean()\n",
        "    std  = series.std()\n",
        "\n",
        "    # Create the histogram\n",
        "    ax = series.hist(\n",
        "        bins    = config.hists.bins,\n",
        "        log     = config.hists.logy,\n",
        "        color   = config.hists.colors.hist,\n",
        "        figsize = config.hists.figsize\n",
        "    )\n",
        "\n",
        "    # Highlight the sigma regions\n",
        "    legend = []\n",
        "    for sigma, colour in config.hists.sigmas.items():\n",
        "        lower_x2, upper_x1 = (mean - sigma * std, mean + sigma * std)\n",
        "        lower_x1, upper_x2 = (mean - (sigma + 1) * std, mean + (sigma + 1) * std)\n",
        "\n",
        "        added = False\n",
        "        if min < lower_x2:\n",
        "            ax.axvspan(lower_x1, lower_x2, color=colour, alpha=0.3)\n",
        "            ticks.add(lower_x1); ticks.add(lower_x2)\n",
        "            added = True\n",
        "        if upper_x1 < max:\n",
        "            ax.axvspan(upper_x1, upper_x2, color=colour, alpha=0.3)\n",
        "            ticks.add(upper_x1); ticks.add(upper_x2)\n",
        "            added = True\n",
        "\n",
        "        if added:\n",
        "            legend.append(Patch(facecolor=colour, label=f'{sigma}σ', alpha=.3, edgecolor='black'))\n",
        "\n",
        "    # Plot the stddev\n",
        "    ax.axvspan(mean, mean, color=config.hists.colors.mean)\n",
        "    ax.axvspan( min,  min, color=config.hists.colors.min )\n",
        "    ax.axvspan( max,  max, color=config.hists.colors.max )\n",
        "\n",
        "    # Change the x-axis ticks to be meaningful\n",
        "    # Change lower x-ticks to the sigma values\n",
        "    ticks.add(mean)\n",
        "    ax.set_xticks(list(ticks), minor=False)\n",
        "\n",
        "    # Add an upper x-ticks for min/max values\n",
        "    ax.xaxis.set_minor_formatter(FormatStrFormatter('%.2f'))\n",
        "    ax.tick_params(which='minor', length=0, labeltop=True, labelbottom=False, top=True)\n",
        "    ax.set_xticks([min, max], minor=True)\n",
        "\n",
        "    # Remove vertical lines from the grid\n",
        "    ax.grid(axis='x', b=False)\n",
        "\n",
        "    # Set some texts\n",
        "    ax.set_title(config.hists.title.format(col=col, bins=config.hists.bins))\n",
        "    ax.set_ylabel(config.hists.ylabel)\n",
        "    ax.set_xlabel(config.hists.xlabel)\n",
        "\n",
        "    if legend:\n",
        "        ax.legend(handles=legend, loc=config.hists.loc)\n",
        "\n",
        "    show(config.hists.file.format(col=col))\n",
        "\n",
        "def time_cadence(df):\n",
        "    \"\"\"\n",
        "    Plots the time cadence of a dataframe, assumes the index is a DateTimeIndex\n",
        "    \"\"\"\n",
        "    flags = {\n",
        "        'kind'   : config.vc.kind,\n",
        "        'title'  : config.vc.title.format(type=config.name),\n",
        "        'ylabel' : config.vc.ylabel,\n",
        "        'xlabel' : 'Cadence (time delta)',\n",
        "        'logy'   : config.vc.logy,\n",
        "        'figsize': config.vc.figsize\n",
        "    }\n",
        "\n",
        "    first   = df.index[0]\n",
        "    last    = df.index[-1]\n",
        "    cadence = df.index.to_series().diff().shift(-1)\n",
        "    mean    = cadence.mean()\n",
        "\n",
        "    print(f'There are {df.index.size} rows of timestamps ranging from {first} to {last}.')\n",
        "    print(f'For this range, the average cadence was {mean}.')\n",
        "\n",
        "    if config.plots.vc:\n",
        "        print('Below is a graph showing other differences in cadences discovered.\\n')\n",
        "\n",
        "        valcou = cadence.value_counts().sort_index()\n",
        "\n",
        "        front, back = config.vc.limits\n",
        "        if valcou.size > front+back:\n",
        "            valcou = pd.concat([valcou[:front], valcou[-back:]])\n",
        "\n",
        "        ax = valcou.plot(**flags)\n",
        "        show(config.vc.file.format(type=config.name))\n",
        "\n",
        "    return first, last, mean\n",
        "\n",
        "def daily_average(col, series):\n",
        "    \"\"\"\n",
        "    Plots the daily average value of each year for a given series\n",
        "    \"\"\"\n",
        "    override = config.davg.overrides.get(config.name, {})\n",
        "\n",
        "    print('\\nThe following graph plots the daily average of each year:\\n')\n",
        "\n",
        "    _, ax = plt.subplots(figsize=config.davg.figsize)\n",
        "\n",
        "    daily = series.resample('1D').mean()    # Take the mean of each day\n",
        "    years = pd.date_range(\n",
        "        f'{series.index[0].year}/1/1',      # From the start of the year of the first timestamp\n",
        "        f'{series.index[-1].year+1}/1/1',   # To the start of the next year after the last timestamp\n",
        "        freq = '1Y',\n",
        "        normalize = True\n",
        "    )\n",
        "    for i, year in enumerate(years):\n",
        "        if i == 0:\n",
        "            data = daily[daily.index <= year]\n",
        "        else:\n",
        "            data = daily[(daily.index > years[i-1]) & (daily.index <= year)]\n",
        "\n",
        "        # Reset the index to day of year to remove the year, and plot\n",
        "        data.index = data.index.dayofyear\n",
        "        ax = data.plot(\n",
        "            label = year.year,\n",
        "            ax    = ax,\n",
        "            alpha = config.davg.alpha,\n",
        "            **override\n",
        "        )\n",
        "\n",
        "    ax.legend()\n",
        "    ax.set_title(config.davg.title.format(col=col))\n",
        "    ax.set_xlabel(config.davg.xlabel)\n",
        "    ax.set_ylabel(config.davg.ylabel)\n",
        "\n",
        "    show(config.davg.file.format(col=col))\n",
        "\n",
        "def analyze(df, drop=True):\n",
        "    \"\"\"\n",
        "    Analyzes a provided dataframe with some generic statistics\n",
        "\n",
        "    Assumptions:\n",
        "    - The index is dtype DateTime\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    df : pandas.DataFrame\n",
        "        The DataFrame to perform analysis on\n",
        "    drop : bool\n",
        "        Drops rows that are entirely null value, eg. resampling the dataframe\n",
        "        can cause new rows to be inserted\n",
        "    \"\"\"\n",
        "    stats = {\n",
        "        'time'   : {},\n",
        "        'values' : {},\n",
        "        'nans'   : {},\n",
        "        'columns': {}\n",
        "    }\n",
        "\n",
        "    # Some integrity checks\n",
        "    assert df.index.is_all_dates\n",
        "    df = df.sort_index()\n",
        "\n",
        "    # Drop rows that are entirely empty\n",
        "    if drop:\n",
        "        df = df.dropna(axis=0, how='all')\n",
        "\n",
        "    # Plot all the data\n",
        "    if config.plots.dvt:\n",
        "        data_vs_time(df)\n",
        "\n",
        "    # Time analysis\n",
        "    stats['time']['first'], stats['time']['last'], stats['time']['mean'] = time_cadence(df)\n",
        "\n",
        "    # Value analysis\n",
        "    stats['values']['totals'] = (~df.isna()*1).sum()\n",
        "    print(f\"\\nThe total values for each column are as follows:\\n{stats['values']['totals']}\")\n",
        "\n",
        "    if config.plots.heat:\n",
        "        print(f'\\nThe correlation of these values between columns are provided in the following heatmap:\\n')\n",
        "        _, ax = plt.subplots(figsize=config.heat.figsize)\n",
        "        ax = sns.heatmap(\n",
        "            df.corr(method=config.heat.method),\n",
        "            annot  = config.heat.annot,\n",
        "            vmin   = config.heat.vmin,\n",
        "            vmax   = config.heat.vmax,\n",
        "            cmap   = config.heat.cmap,\n",
        "            square = config.heat.square,\n",
        "            ax     = ax\n",
        "\n",
        "        )\n",
        "        ax.set_title(config.heat.title.format(name=config.name, type='Values'))\n",
        "        show(config.heat.file.format(type='value'))\n",
        "\n",
        "    ## NaN analysis\n",
        "    nandf   = df.isna() * 1 # Converts bools to binary\n",
        "    nancorr = nandf.corr(method=config.heat.method)\n",
        "    stats['nans']['totals'] = nandf.sum()\n",
        "\n",
        "    print(f\"The total NaNs for each column are as follows:\\n{stats['nans']['totals']}\")\n",
        "    if nancorr.any().any() and config.plots.heat:\n",
        "        print(f'\\nThe correlation of the positions of these nans between columns are provided in the following heatmap:\\n')\n",
        "\n",
        "        _, ax = plt.subplots(figsize=config.heat.figsize)\n",
        "        ax = sns.heatmap(\n",
        "            nancorr,\n",
        "            annot  = config.heat.annot,\n",
        "            vmin   = config.heat.vmin,\n",
        "            vmax   = config.heat.vmax,\n",
        "            cmap   = config.heat.cmap,\n",
        "            square = config.heat.square,\n",
        "            ax     = ax\n",
        "        )\n",
        "        ax.set_title(config.heat.title.format(name=config.name, type='NaNs'))\n",
        "        show(config.heat.file.format(type='nan'))\n",
        "\n",
        "    ### Per column analysis\n",
        "    for col in df.columns:\n",
        "        print(f'\\nANALYZING {col}')\n",
        "        stats['columns'][col] = {}\n",
        "        series = df[col]\n",
        "\n",
        "        # Distance between values\n",
        "        valinds = series[~series.isna()].index.to_series()\n",
        "        cadence = valinds.diff().shift(-1)\n",
        "        valcou  = cadence.value_counts().sort_index()\n",
        "\n",
        "        stats['columns'][col]['percent']      = (valinds.size / series.size) * 100\n",
        "        stats['columns'][col]['total']        = series.size\n",
        "        stats['columns'][col]['value count']  = valinds.size\n",
        "        stats['columns'][col]['nan count']    = series.size - valinds.size\n",
        "        stats['columns'][col]['cadence mean'] = cadence.mean()\n",
        "\n",
        "        print(f\"The column is {stats['columns'][col]['percent']:.2f}% dense, {valinds.size} / {series.size}\")\n",
        "        print(f\"The average distance between values is {stats['columns'][col]['cadence mean']}.\")\n",
        "\n",
        "        if config.plots.vc:\n",
        "            print(' Below is a graph showing the various differences in distances between values:\\n')\n",
        "\n",
        "            flags = {\n",
        "                'kind'   : config.vc.kind,\n",
        "                'title'  : config.vc.title.format(type=col),\n",
        "                'ylabel' : config.vc.ylabel,\n",
        "                'xlabel' : 'Time Delta between Values',\n",
        "                'logy'   : config.vc.logy,\n",
        "                'figsize': config.vc.figsize\n",
        "            }\n",
        "            front, back = config.vc.limits\n",
        "            if valcou.size > front+back:\n",
        "                valcou = pd.concat([valcou[:front], valcou[-back:]])\n",
        "\n",
        "            ax = valcou.plot(**flags)\n",
        "            show(config.vc.file.format(type=col))\n",
        "\n",
        "        if config.plots.davg:\n",
        "            daily_average(col, series)\n",
        "\n",
        "        # Outliers\n",
        "        if config.plots.hists:\n",
        "            print('\\nThe follow graph is a histogram of the given column with the standard deviation regions away from the mean highlighted to show outliers.')\n",
        "            print('The red vertical line is the mean of the column, and each highlighted region is N standard deviations away.')\n",
        "            print('The lower x-axis mark the boundaries of these sigma regions. The upper x-axis mark the min/max values for the series.')\n",
        "            sigma_hist(col, series)\n",
        "\n",
        "    return stats\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loader = lambda: pd.DataFrame()\n",
        "if config.name is 'weather':\n",
        "    loader = partial(load_weather, interpolate=False)\n",
        "elif config.name is 'bls':\n",
        "    loader = partial(load_bls, datenum=True, round=True, drop_dups=True)\n",
        "elif config.name is 'r0_day':\n",
        "    loader = partial(load_r0, kind='day', datenum=True, round=True)\n",
        "elif config.name is 'r0_night':\n",
        "    loader = partial(load_r0, kind='night', datenum=True, round=True)\n",
        "\n",
        "df = loader(path=config.path)\n",
        "\n",
        "if df.empty:\n",
        "    print('Error! The dataframe is empty!')\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stats = analyze(df, drop=True)\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This line checks if there's any duplicate index values in the dataframe\n",
        "df[df.index.duplicated(keep=False)]\n",
        "\n",
        "# This will show some of the column stats in a prettier format\n",
        "pd.DataFrame(stats['columns'])"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "argv": [
        "/Users/jamesmo/miniconda3/envs/mloc/bin/python",
        "-m",
        "ipykernel_launcher",
        "-f",
        "{connection_file}"
      ],
      "display_name": "mloc",
      "language": "python",
      "name": "mloc"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}