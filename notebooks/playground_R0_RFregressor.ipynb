{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### import statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "sys.path.append('../src')\n",
    "# from utils import load_weather\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from scipy.stats import gaussian_kde\n",
    "import seaborn as sns\n",
    "import scipy.stats as stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F_INPUT = '../../data/data.merged.pandas.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "feats = ['pressure', 'relative_humidity', 'temperature', 'wind_speed', 'month', 'Cn2', 'solar_zenith_angle','day']\n",
    "label = 'r0'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_hdf(F_INPUT, 'resampled/median')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### add new features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['month'] = df['datenum'].index.month\n",
    "df['day'] = df['datenum'].index.dayofyear"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### restricting data to usable, relatively dense subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_subset = df[(df.index >= '2018-10-01') & (df.index < '2019-01-01')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_subset.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### finding non-nan values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "valid = ~df_subset.isnull().any(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_subset[valid].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### splitting into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train = df_subset.index <= '2018-12-10'\n",
    "test  = df_subset.index > '2018-12-10'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_subset.loc[train & valid,feats].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_subset.loc[test & valid,feats].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### initializing the RF regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "regr = RandomForestRegressor(n_estimators=100, random_state=0)\n",
    "regr.fit(df_subset.loc[train&valid,feats], df_subset.loc[train&valid,label])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### predict on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "preds = regr.predict(df_subset.loc[test&valid,feats])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "r2 = regr.score(df_subset.loc[test&valid,feats], df_subset.loc[test&valid,label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def error_diff(targ, pred):\n",
    "    return targ-pred\n",
    "def error_perc(targ, pred):\n",
    "    return (targ-pred)/targ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "r0_bins = np.arange(0,25,0.5)\n",
    "act_pred_scatter_xbins, act_pred_scatter_ybins = np.meshgrid(r0_bins, r0_bins)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### scatter plots of actual vs. predict using error_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(20, 10))\n",
    "s = 25\n",
    "a = 0.4\n",
    "ax[0].scatter(df_subset.loc[test&valid,label],\n",
    "           preds,\n",
    "           edgecolor='k', c=\"cornflowerblue\", s=s, alpha=a)\n",
    "# ax[0].hist2d(df_subset.loc[test&valid,label],\n",
    "#            preds,act_pred_scatter_bins, cmap='jet')\n",
    "x = np.linspace(df_subset.loc[test&valid,label].min(), df_subset.loc[test&valid,label].max(), 1000)\n",
    "ax[0].plot(x, x, 'r-')\n",
    "ax[0].set_xlabel(\"Actual r0\")\n",
    "ax[0].set_ylabel(\"Predicted r0\")\n",
    "ax[0].set_xticks(np.arange(0, 25))\n",
    "ax[0].set_yticks(np.arange(0, 25))\n",
    "\n",
    "ax[1].scatter(df_subset.loc[test&valid,label],\n",
    "              error_diff(df_subset.loc[test&valid,label], preds),\n",
    "              edgecolor='k', c=\"forestgreen\", s=s, alpha=a)\n",
    "ax[1].plot(x, np.zeros(x.shape), 'r-')\n",
    "ax[1].set_xlabel(\"Actual r0\")\n",
    "ax[1].set_ylabel(\"Error r0\")\n",
    "ax[1].set_xticks(np.arange(0, 25))\n",
    "\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### scatter plots of actual vs. predict using error_perc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(20, 10))\n",
    "s = 25\n",
    "a = 0.4\n",
    "ax[0].scatter(df_subset.loc[test&valid,label],\n",
    "           preds,\n",
    "           edgecolor='k', c=\"cornflowerblue\", s=s, alpha=a)\n",
    "# ax[0].hist2d(df_subset.loc[test&valid,label],\n",
    "#            preds,act_pred_scatter_bins, cmap='jet')\n",
    "x = np.linspace(df_subset.loc[test&valid,label].min(), df_subset.loc[test&valid,label].max(), 1000)\n",
    "ax[0].plot(x, x, 'r-')\n",
    "ax[0].set_xlabel(\"Actual r0\")\n",
    "ax[0].set_ylabel(\"Predicted r0\")\n",
    "ax[0].set_xticks(np.arange(0, 25))\n",
    "ax[0].set_yticks(np.arange(0, 25))\n",
    "\n",
    "ax[1].scatter(df_subset.loc[test&valid,label],\n",
    "              error_perc(df_subset.loc[test&valid,label], preds),\n",
    "              edgecolor='k', c=\"forestgreen\", s=s, alpha=a)\n",
    "ax[1].plot(x, np.zeros(x.shape), 'r-')\n",
    "ax[1].set_xlabel(\"Actual r0\")\n",
    "ax[1].set_ylabel(\"Perc Error r0\")\n",
    "ax[1].set_xticks(np.arange(0, 25))\n",
    "\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### time domain plot of errors\n",
    "\n",
    "switching matplotlib to notebook mode to enable a zoom-in of different portions of the time axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook \n",
    "fig, ax = plt.subplots(3, 1)\n",
    "ax[0].plot(df_subset.loc[test&valid,label].index, df_subset.loc[test&valid,label], 'gx', label='actual')\n",
    "ax[0].plot(df_subset.loc[test&valid,label].index, preds, 'ro', label='predicted')\n",
    "ax[0].set_xlabel(\"Datetime\")\n",
    "ax[0].set_ylabel(\"r0\")\n",
    "ax[0].legend()\n",
    "\n",
    "ax[1].plot(df_subset.loc[test&valid,label].index, error_diff(df_subset.loc[test&valid,label], preds), 'bx')\n",
    "ax[1].set_xlabel(\"Datetime\")\n",
    "ax[1].set_ylabel(\"error r0\")\n",
    "\n",
    "ax[2].plot(df_subset.loc[test&valid,label].index, error_perc(df_subset.loc[test&valid,label], preds), 'bx')\n",
    "ax[2].set_xlabel(\"Datetime\")\n",
    "ax[2].set_ylabel(\"perc error r0\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### feature importance\n",
    "\n",
    "feature importance from the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "def plot_importance(forest, X, featnames):\n",
    "    importances = forest.feature_importances_\n",
    "    std = np.std([tree.feature_importances_ for tree in forest.estimators_],\n",
    "                 axis=0)\n",
    "    indices = np.argsort(importances)[::-1]\n",
    "\n",
    "    # Print the feature ranking\n",
    "    print(\"Feature ranking:\")\n",
    "\n",
    "    for f in range(X.shape[1]):\n",
    "        print(f\"{f + 1}. {featnames[indices[f]]:20} ({importances[indices[f]]})\")\n",
    "\n",
    "    # Plot the impurity-based feature importances of the forest\n",
    "    plt.figure()\n",
    "    plt.title(\"Feature importances\")\n",
    "    plt.bar(range(X.shape[1]), importances[indices],\n",
    "            color=\"r\", yerr=std[indices], align=\"center\")\n",
    "    plt.xticks(range(X.shape[1]), [ featnames[i] for i in indices ], rotation='vertical')\n",
    "    plt.xlim([-1, X.shape[1]])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_importance(regr, df_subset.loc[train&valid,feats], feats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### debug why CN2 is so low\n",
    "\n",
    "1. What happens if I drop month and SZA\n",
    "2. Let's look at correlation between the signals using [stats.pearsonr](https://towardsdatascience.com/four-ways-to-quantify-synchrony-between-time-series-data-b99136c4a9c9)\n",
    "\n",
    "We calculate:\n",
    "- overall synchrony between r0 and Cn2\n",
    "- local synchrony between r0 and Cn2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Overall Synchrony"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_pearson_r = df_subset.loc[train&valid,feats].corr().iloc[0,1]\n",
    "print(f\"Pandas computed Pearson r: {overall_pearson_r}\")\n",
    "\n",
    "r, p = stats.pearsonr(df_subset.loc[train&valid,label], df_subset.loc[train&valid,'Cn2'])\n",
    "print(f\"Scipy computed Pearson r: {r} and p-value: {p}\")\n",
    "# # out: Scipy computed Pearson r: 0.20587745135619354 and p-value: 3.7902989479463397e-51\n",
    "\n",
    "# Compute rolling window synchrony\n",
    "f,ax=plt.subplots(2, 1, figsize=(7,3), sharex=True)\n",
    "ax[0].plot(df_subset.loc[train&valid,label], label=label)\n",
    "ax[1].plot(df_subset.loc[train&valid,['Cn2']], label='Cn2')\n",
    "# ax[1].set(title=f\"Overall Pearson r = {np.round(r,2)}\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Local Synchrony"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set window size to compute moving window synchrony.\n",
    "r_window_size = 120\n",
    "# Compute rolling window synchrony\n",
    "rolling_r = df_subset.loc[train&valid,label].rolling(window=r_window_size, center=True).corr(df_subset.loc[train&valid,'Cn2'])\n",
    "f,ax=plt.subplots(3,1,figsize=(14,6),sharex=True)\n",
    "ax[0].plot(df_subset.loc[train&valid,label], label=label)\n",
    "ax[1].plot(df_subset.loc[train&valid,['Cn2']], label='Cn2')\n",
    "rolling_r.plot(ax=ax[2])\n",
    "ax[0].set(ylabel='r0')\n",
    "ax[1].set(ylabel='Cn2')\n",
    "ax[2].set(ylabel='Pearson r')\n",
    "plt.suptitle(\"Smiling data and rolling window correlation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
