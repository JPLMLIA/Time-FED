# This file was generated by mlky
# Usage: --config [this file].yml --patch "generated" --defs definitions.yml
#
# mlky uses special syntax ${?key} to perform value replacement operations at runtime:
#   ${key} = Replace this ${} in the string with the value at config[key]
#   ${$key} = Replace this ${} in the string with the environment variable `key`
#   ${?key} = Replace this ${} in the string with the str(return) from function `key` in the registered functions
#   ${!key} = Replace this value with the return from function `key` in the registered functions
#
# Additionally, mlky enables special keys for certain types:
#         \ = mlky.Null, this is equivalent to deleting the key from the config altogether
#
# The "K" column is the key column indicating what type of key this is:
#         ! = This key is required to be manually set
#         ? = This is an optional key under a required section
#   <blank> = Fully optional, can remove from config with no repercussions

generated:                    # K | dtype | Short description
  cores: ${!os.cpu_count}     #   | int   | Number of cores to use for multiprocessing
  log:                        #   | dict  | Controls the logger
    file: timefed.log         #   | str   | File to write log outputs to. Omit to not write to file
    mode: write               #   | str   | File write mode, ie: `write` = overwite the file, `append` = append to existing
    level: DEBUG              #   | str   | Logger level. This is the level that will write to file if enabled
    terminal: ${log.level}   #   | str   | The terminal level to log, ie. logger level to write to terminal. This can be different than the file level
    mlflow: false             #   | bool  | Enables MLFlow logging
  preprocess:                 #   | dict  | Options for the DSN `preprocess` module
    enabled: true             # ! | bool  | Enables/disables this module in a pipeline execution
    kind: dsn                 # ! | str   | Which preprocess module to use
    file: preprocess.h5       # ! | str   | Path to an H5 file to write to
    tracks: \                 # ! | str   | Path to a DSN tracks file
    drs: \                    # ! | str   | Path to a DSN DRs file
    skip_dcc: false           #   | bool  | Skips tracks with multiple DCC channels
    only:                     #   | dict  | Only process these:
      missions: []            #   | list  | Missions to select in the tracks file
      drs: []                 #   | list  | DRs to select from the DRs file
    features:                 #   | dict  | Creates additional features from a predefined set of functions
      diff: []                #   | list  | Executes DataFrame[feature].diff(): First discrete difference of element
    concat: true              #   | bool  | Enables concatenation of multiple missions' outputs together
    subsample:                #   | dict  | Subsampling strategies to balance the negative:positive ratio in classification cases
      query: \                #   | str   | Passes a query string to DataFrame.query()
      pos_limit: \            #   | int   | Total number of positive tracks to randomly select
      neg_limit: \            #   | int   | Total number of negative tracks to randomly select
      neg_ratio: \            #   | int   | N:1 ratio of negative:positive tracks
  extract:                    #   | dict  | Options for the `extract` module
    enabled: true             # ! | bool  | Enables/disables this module in a pipeline execution
    cores: ${cores}          #   | int   | Number of cores to use for the extract module
    file: ${preprocess.file} # ! | str   | Path to an H5 file to write to
    multi: \                  #   |       | Processes a stream of multiple input tracks. This is either a str to which the tracks reside under in the input file, or a list of specific keys in the file to grab
    flush: false               #   | bool  | Flushes processed windows to disk to relieve held memory
    roll:                     #   | dict  | Parameters for the roll function
      window: \               # ! | str   | Size of the windows to extract. The size of these windows is determined by this value divided by the frequency of the data, eg. 10min / 1min = 10 samples. This a is a string compatible with pandas.Timedelta().
      frequency: \            # ! |       | The sampling frequency of the data. If not set, the frequency will be assumed to be the largest quantity of differences between timestamps. This a is a string compatible with pandas.Timedelta().
      step: 1                 #   |       | Size of the step when moving from one window to the next. This can be either an int or a str, where an int would step N many indices from the start of the previous window's start, and str would step N amount of time beyond the start of the previous window's start.
      required: []            #   | list  | List of required variables when rolling. If not provided, defaults to all variables.
      optional: []            #   | list  | List of optional variables when rolling. If not provided, defaults to the opposite of `required`.
    columns: []               #   | list  | Only process these columns through tsfresh extraction. Defaults to all columns if not provided.
    index: -1                 #   | int   | Which index of a window to set as the window index. Defaults to the last index of the window.
    features:                 #   | dict  | Contains the arguments for selecting which tsfresh features to process
      interactive: false      #   | bool  | Enables interactive mode for selection of feature functions from `tsfresh.feature_extraction.ComprehensiveFCParameters`
      whitelist: []           #   | list  | Name of feature functions to accept from `tsfresh.feature_extraction.ComprehensiveFCParameters`
      blacklist: []           #   | list  | Name of feature functions to reject from `tsfresh.feature_extraction.ComprehensiveFCParameters`
  subselect:                  #   | dict  | Options for the `subselect` module
    enabled: true             # ! | bool  | Enables/disables this module in a pipeline execution
    cores: ${cores}          #   | int   | Number of cores to use for the extract module
    file: ${preprocess.file} # ! | str   | Path to an H5 file to write to
    split_date: \             #   | str   | Split date to use if not in interactive mode
    interactive: true         #   | bool  | Enables interactive mode for selecting a split date to use
    metadata: metadata.pkl    # ! | str   | Path to a .pkl file to handle classification metadata (not used in regression)
  model:                      #   | dict  | Options for the `model` module
    enabled: true             # ! | bool  | Enables/disables this module in a pipeline execution
    type: regression          # ! | str   | Defines what kind of model this data would use. This influences many functions of TimeFED
    file: ${preprocess.file} # ! | str   | Path containing the train and set sets (under keys select/[train,test]) (pandas h5 format)
    model:                    #   | dict  | Options for controlling the model creation
      file: null              #   | str   | Path to a model pickle file. If this file does not exists, this will be the path to write to if output.model is enabled
      overwrite: true         #   | bool  | If a model file already exists, this enables overwriting that file
      fit: true               #   | bool  | Enables calling model.fit() on the training dataset
    output:                   #   | dict  | Options for enabling/disabling various outputs
      model: true             #   | bool  | Enables saving the model
      predicts: predicts.h5   #   | str   | Path to write predict values to (pandas h5 format)
      scores: scores.h5       #   | str   | Path to write scores to (dict in pickle format)
    train_scores: false       #   | bool  | Perform scoring on the train set

# Usage: python pipeline.py -c gen.yml -p "generated<-mms"
base:
  mlky.patch: generated
  name: base-run
  log:
    file: ${output}/${name}.log
    mode: append
  preprocess:
    enabled: true
    file: ${output}/${name}.h5
    tracks: ${data}/v4.MMS.tracks.h5
    drs: ${data}/v3.drs.h5
    only:
      drs:
        - RFI
        - SC
    features:
      diff:
        - CARRIER_SYSTEM_NOISE_TEMP
        - AGC_VOLTAGE
    subsample:
      neg_ratio: 1
  extract:
    enabled: true
    method: tsfresh
    roll:
      window: 5 min
      frequency: null
    columns:
      - diff_CARRIER_SYSTEM_NOISE_TEMP
      - diff_AGC_VOLTAGE
  subselect:
    enabled: true
    interactive: true
    file: ${preprocess.file}
    parquet: ${output}/extract.pqt/
    metadata: ${output}/${name}.metadata.pkl
    features: .*(CARRIER_SYSTEM_NOISE_TEMP|AGC_VOLTAGE).*
  model:
    enabled: true
    target: Label
    type: classification
    file: ${preprocess.file}
    model:
      file: ${output}/${name}.model.pkl
    output:
      model: true
      scores: ${output}/${name}.scores.pkl
      predicts: ${output}/${name}.predicts.h5

# SYSTEMS

local:
  mlky.patch: base
  input: \
  output: \
  data: \


mlia:
  mlky.patch: base
  input: /data/MLIA_active_data/timefed/experiments
  output: /data/MLIA_active_data/timefed/experiments
  data: /data/MLIA_active_data/timefed/experiments


gattaca:
  mlky.patch: base
  input: /scratch-edge/sudsaq/timefed/data
  output: /scratch-edge/sudsaq/timefed/jobs/${name}/output/
  data: /scratch-edge/sudsaq/timefed/data
  preprocess:
    tracks: ${data}/mms.tracks.h5
    drs: ${data}/mms.drs.h5

# UTILITY

# Reduces the verbosity of the terminal log but the file logs will still be default (debug)
quiet:
  log:
    terminal: INFO

# RUNS

test:
  mlky.patch: base
  name: mms

  preprocess:
    enabled: false
    only:
      missions:
        - MMS1

  extract:
    enabled: true
    flush: false
    method: tsfresh
    parquet: ${output}/extract.pqt/
    # roll:
    #   window: 25 min
    columns:
      - diff_CARRIER_SYSTEM_NOISE_TEMP
      - diff_AGC_VOLTAGE

  subselect:
    enabled: false
    interactive: true
    split_date: 2018-08-14

  model:
    enabled: false


mms:
  name: mms
  preprocess:
    only:
      missions:
        - MMS1
        - MMS2
        - MMS3
        - MMS4
  extract:
    parquet: ${output}/extract.pqt/
  subselect:
    interactive: false
    split_date: 2018-10-16


mms1:
  name: mms1
  preprocess:
    only:
      missions:
        - MMS1
  subselect:
    interactive: false
    split_date: 2018-10-16


gnss:
  name: multi_gnss
  output: /Users/jamesmo/projects/timefed/TimeFED/timefed/local/data/
  preprocess:
    enabled: false
    file: ${output}/gnss_multi.h5
    tracks: ${output}/preprocess.gnss.h5
    drs: ${output}/preprocess.gnss.h5

  extract:
    enabled: true
    method: passthrough
    roll:
      window: 14D
      frequency: null
      step: 7D
    columns: []
    multi: preprocess
    save_as_multi: true
  subselect:
    enabled: false
    metadata: ${output}/metadata.gnss.pkl
    multi: true
    output: xarray

  model:
    enabled: false
    target: Label
    type: classification
    model:
      file: ${output}/model.gnss.pkl


gnss-multi:
  name: multi_gnss
  preprocess:
    enabled: false
    file: ${input}/multi_ridge_gnss.h5
  extract:
    enabled: true
    method: tsfresh
    parquet: ${output}/extract.pqt/
    roll:
      window: 21D
      frequency: null
      step: 1D
    columns:
      - N
      - E
    multi: preprocess
    save_as_multi: true
    blocks:
      min: 64
  subselect:
    enabled: true
    metadata: ${output}/metadata.gnss.pkl
    multi: true
    output: pandas
    interactive: false
    split_date: 2018-12-31
  model:
    enabled: true
    target: Label
    type: classification
    model:
      file: ${output}/model.gnss.pkl
