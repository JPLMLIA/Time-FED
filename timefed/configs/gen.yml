generated:                          #   | dict  | Generated via mlky toYaml
  cores: ${!os.cpu_count}           #   | int   | Number of cores to use for multiprocessing
  log:                              #   | dict  | Controls the logger
    file: timefed.log               #   | str   | File to write log outputs to. Omit to not write to file
    mode: write                     #   | str   | File write mode, ie: `write` = overwite the file, `append` = append to existing
    level: DEBUG                    #   | str   | Logger level. This is the level that will write to file if enabled
    terminal: ${.level}             #   | str   | The terminal level to log, ie. logger level to write to terminal. This can be different than the file level
    mlflow: False                   #   | bool  | Enables MLFlow logging
  preprocess:                       #   | dict  | Options for the DSN `preprocess` module
    enabled: True                   # * | bool  | Enables/disables this module in a pipeline execution
    kind: dsn                       # * | str   | Which preprocess module to use
    file: preprocess.h5             # * | str   | Path to an H5 file to write to
    tracks: \                       #   | str   | Path to a DSN tracks file
    drs: \                          #   | str   | Path to a DSN DRs file
    skip_dcc: False                 #   | bool  | Skips tracks with multiple DCC channels
    only:                           #   | dict  | Only process these:
      missions: []                  #   | list  | Missions to select in the tracks file
      drs: []                       #   | list  | DRs to select from the DRs file
    features:                       #   | dict  | Creates additional features from a predefined set of functions
      diff: []                      #   | list  | Executes DataFrame[feature].diff(): First discrete difference of element
    concat: True                    #   | bool  | Enables concatenation of multiple missions' outputs together
    subsample:                      #   | dict  | Subsampling strategies to balance the negative:positive ratio in classification cases
      seed: 0                       #   | int   | Random seed to set for numpy.random.seed()
      query: \                      #   | str   | Passes a query string to DataFrame.query()
      pos_limit: \                  #   | int   | Total number of positive tracks to randomly select
      neg_limit: \                  #   | int   | Total number of negative tracks to randomly select
      neg_ratio: \                  #   | int   | N:1 ratio of negative:positive tracks
  extract:                          #   | dict  | Options for the `extract` module
    enabled: True                   # * | bool  | Enables/disables this module in a pipeline execution
    cores: ${cores}                 #   | int   | Number of cores to use for the extract module
    method: tsfresh                 # * | str   | Window processing method
    file: ${preprocess.file}        # * | str   | Path to an H5 file to write to
    parquet: ${preprocess.file}.pqt # * | str   | Path to write the intermediary parquet
    multi: \                        #   | any   | Processes a stream of multiple input tracks. This is either a str to which the tracks reside under in the input file, or a list of specific keys in the file to grab
    blocks:                         #   | dict  | Defines the min/max block range for repartitioning. An ideal block size will attempt to be discovered in this range
      min: 20                       #   | int   | Minimum block size. If this is too small compared to the number of windows extracted, the system may perform poorly
      max: 0.1                      #   | float | Maximum block size. If int, uses this with the min to create a range. If float, multiplies this with the total number of windows to create the max
    roll:                           #   | dict  | Parameters for the roll function
      window: \                     # * | str   | Size of the windows to extract. The size of these windows is determined by this value divided by the frequency of the data, eg. 10min / 1min = 10 samples. This a is a string compatible with pandas.Timedelta().
      frequency: \                  # * | any   | The sampling frequency of the data. If not set, the frequency will be assumed to be the largest quantity of differences between timestamps. This a is a string compatible with pandas.Timedelta().
      step: 1                       #   | any   | Size of the step when moving from one window to the next. This can be either an int or a str, where an int would step N many indices from the start of the previous window's start, and str would step N amount of time beyond the start of the previous window's start.
      required: []                  #   | list  | List of required variables when rolling. If not provided, defaults to all variables.
      optional: []                  #   | list  | List of optional variables when rolling. If not provided, defaults to the opposite of `required`.
    columns: []                     #   | list  | Only process these columns through tsfresh extraction. Defaults to all columns if not provided.
    index: -1                       #   | int   | Which index of a window to set as the window index. Defaults to the last index of the window.
    features:                       #   | dict  | Contains the arguments for selecting which tsfresh features to process
      interactive: False            #   | bool  | Enables interactive mode for selection of feature functions from `tsfresh.feature_extraction.ComprehensiveFCParameters`
      whitelist: []                 #   | list  | Name of feature functions to accept from `tsfresh.feature_extraction.ComprehensiveFCParameters`
      blacklist: []                 #   | list  | Name of feature functions to reject from `tsfresh.feature_extraction.ComprehensiveFCParameters`
  subselect:                        #   | dict  | Options for the `subselect` module
    enabled: True                   # * | bool  | Enables/disables this module in a pipeline execution
    cores: ${cores}                 #   | int   | Number of cores to use for the extract module
    file: ${preprocess.file}        # * | str   | Path to an H5 file to write to
    split_date: \                   #   | any   | Split date to use if not in interactive mode
    interactive: True               #   | bool  | Enables interactive mode for selecting a split date to use
    metadata: metadata.pkl          # * | str   | Path to a .pkl file to handle classification metadata (not used in regression)
    tsfresh: True                   #   | bool  | Enables/disables the tsfresh.feature_selection on the train dataframe. Only applies to pandas DataFrames
    output: pandas                  #   | str   | Output type for multi-track cases: pandas = Stacked DataFrames, xarray = 3D (track ID, window index, feature)
  model:                            #   | dict  | Options for the `model` module
    enabled: True                   # * | bool  | Enables/disables this module in a pipeline execution
    type: regression                # * | str   | Defines what kind of model this data would use. This influences many functions of TimeFED
    file: ${preprocess.file}        # * | str   | Path containing the train and set sets (under keys select/[train,test]) (pandas h5 format)
    model:                          #   | dict  | Options for controlling the model creation
      file: None                    #   | str   | Path to a model pickle file. If this file does not exists, this will be the path to write to if output.model is enabled
      overwrite: True               #   | bool  | If a model file already exists, this enables overwriting that file
      fit: True                     #   | bool  | Enables calling model.fit() on the training dataset
    output:                         #   | dict  | Options for enabling/disabling various outputs
      model: True                   #   | bool  | Enables saving the model
      predicts: predicts.h5         #   | str   | Path to write predict values to (pandas h5 format)
      scores: scores.h5             #   | str   | Path to write scores to (dict in pickle format)
    train_scores: False             #   | bool  | Perform scoring on the train set


# Default Overrides

default:
  mlky.patch: generated
  name: default
  log:
    file: ${output}/${name}.log
  preprocess:
    file: ${output}/${name}.h5
  subselect:
    metadata: ${output}/${name}.metadata.pkl
  model:
    model:
      file: ${output}/${name}.model.pkl
    output:
      scores: ${output}/${name}.scores.pkl
      predicts: ${output}/${name}.predicts.h5


# Systems

local:
  mlky.patch: default
  input: .
  output: .
  data: .


mlia:
  mlky.patch: default
  input: /data/MLIA_active_data/timefed/experiments
  output: /data/MLIA_active_data/timefed/experiments
  data: /data/MLIA_active_data/timefed/experiments


gattaca:
  mlky.patch: default
  input: /scratch-edge/sudsaq/timefed/data
  output: /scratch-edge/sudsaq/timefed/jobs/${name}/output/
  data: /scratch-edge/sudsaq/timefed/data
  preprocess:
    tracks: ${data}/mms.tracks.h5
    drs: ${data}/mms.drs.h5


# Runs

mms:
  name: mms

  preprocess:
    tracks: ${data}/v4.MMS.tracks.h5
    drs: ${data}/v3.drs.h5
    only:
      drs:
        - RFI
        - SC
    features:
      diff:
        - CARRIER_SYSTEM_NOISE_TEMP
        - AGC_VOLTAGE
    subsample:
      neg_ratio: 1

  extract:
    roll:
      window: 5 min
      frequency: null
    columns:
      - diff_CARRIER_SYSTEM_NOISE_TEMP
      - diff_AGC_VOLTAGE

  subselect:
    interactive: false
    split_date: 2018-10-16
    features: .*(CARRIER_SYSTEM_NOISE_TEMP|AGC_VOLTAGE).*

  model:
    target: Label
    type: classification


mms1:
  mlky.patch: mms
  name: mms1
  preprocess:
    only:
      missions:
        - MMS1


gnss:
  name: gnss

  preprocess:
    enabled: false
    file: ${output}/gnss_multi.h5

  extract:
    enabled: true
    method: passthrough
    roll:
      window: 14D
      frequency: null
      step: 7D
    columns: []
    multi: preprocess
    save_as_multi: true

  subselect:
    enabled: false
    metadata: ${output}/metadata.gnss.pkl
    multi: true
    output: xarray

  model:
    enabled: false
    target: Label
    type: classification
    model:
      file: ${output}/model.gnss.pkl


gnss-multi:
  name: multi_gnss

  preprocess:
    enabled: false
    file: ${input}/multi_ridge_gnss.h5

  extract:
    enabled: true
    method: tsfresh
    parquet: ${output}/extract.pqt/
    roll:
      window: 21D
      frequency: null
      step: 1D
    columns:
      - N
      - E
    multi: preprocess
    save_as_multi: true
    blocks:
      min: 64

  subselect:
    enabled: true
    metadata: ${output}/metadata.gnss.pkl
    multi: true
    output: pandas
    interactive: false
    split_date: 2018-12-31
    features: \

  model:
    enabled: true
    target: Label
    type: classification
    model:
      file: ${output}/model.gnss.pkl


# Utilities

# Reduces the verbosity of the terminal log but the file logs will still be default (debug)
quiet:
  log:
    terminal: INFO


interactive:
  subselect:
    interactive: true


rotate:
  extract:
    method: rotate
  subselect:
    tsfresh: false
